{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c4b950-507d-4e90-a844-c02613502cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "\n",
    "# ===== í™˜ê²½ ì„¤ì • =====\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai.Client()\n",
    "\n",
    "# íƒœë„/ëª¨ë²”/ì„±ì‹¤ ì¹­ì°¬ë§Œ ì œê±° (ì§ˆë¬¸ ì¶œì²˜ë¡œëŠ” ì“°ì§€ ì•Šê¸° ìœ„í•¨)\n",
    "EXCLUDE_KEYWORDS = [\n",
    "    \"ì„±ì‹¤\", \"ì„±ì‹¤í•¨\", \"ì„±ì‹¤í•˜ê²Œ\", \"ëª¨ë²”\", \"ëª¨ë²”ì ì¸\",\n",
    "    \"íƒœë„\", \"íƒœë„ê°€\", \"ìì„¸ê°€ ì¢‹\", \"ì •ì„±ì„ ë‹¤í•´\",\n",
    "    \"ë°œí‘œí•œ ëª¨ìŠµì´ ë³´ê¸° ì¢‹ì•˜\", \"ë°œí‘œë¥¼ ì˜í•¨\", \"ë°œí‘œë¥¼ ì˜ í•˜\",\n",
    "    \"ì°¸ì—¬ë„ê°€ ë†’\", \"ì—´ì‹¬íˆ ì°¸ì—¬\", \"ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬\",\n",
    "    \"ì¹œêµ¬ë“¤ê³¼ ì˜ ì§€ë‚´\", \"ë´‰ì‚¬ì •ì‹ ì´ íˆ¬ì² \", \"ì˜ˆì˜ë°”ë¥¸ íƒœë„\"\n",
    "]\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 1. ì „ì²´ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°\n",
    "##########################################################\n",
    "def get_full_text(student_data):\n",
    "    \"\"\"academic_records + readingì„ í•˜ë‚˜ì˜ í° í…ìŠ¤íŠ¸ë¡œ í•©ì¹¨\"\"\"\n",
    "    records = student_data.get(\"academic_records\", [])\n",
    "    if isinstance(records, list):\n",
    "        full = \"\\n\".join(str(x) for x in records)\n",
    "    else:\n",
    "        full = str(records)\n",
    "\n",
    "    reading = student_data.get(\"reading\", \"\")\n",
    "    if reading:\n",
    "        full += \"\\n\" + str(reading)\n",
    "\n",
    "    return full\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 2. í¬ë§ë¶„ì•¼ â†’ í•™ë…„ë³„ ìë™ ë°°ì • (1,2,3í•™ë…„ ìˆœì„œëŒ€ë¡œ)\n",
    "##########################################################\n",
    "def extract_career_by_grade(full_text):\n",
    "    \"\"\"\n",
    "    'í¬ë§ ë¶„ì•¼ ~~~' ê°€ ë“±ì¥í•˜ëŠ” ìˆœì„œëŒ€ë¡œ\n",
    "    1í•™ë…„, 2í•™ë…„, 3í•™ë…„ì— ë§¤ì¹­í•œë‹¤ê³  ê°€ì •.\n",
    "    \"\"\"\n",
    "    matches = re.findall(r\"í¬ë§\\s*ë¶„ì•¼\\s*([^\\n]+)\", full_text)\n",
    "\n",
    "    grade_raw = {1: None, 2: None, 3: None}\n",
    "    for idx, raw in enumerate(matches[:3], start=1):\n",
    "        cleaned = raw.replace(\"ë¶„ì•¼\", \"\").replace(\"ê³„ì—´\", \"\").strip()\n",
    "        grade_raw[idx] = cleaned\n",
    "\n",
    "    return grade_raw\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 3. ì„¸íŠ¹/ì°½ì²´ ì¶œì²˜ ìë™ ì¶”ì¶œ\n",
    "##########################################################\n",
    "def extract_sources(full_text):\n",
    "    \"\"\"\n",
    "    - 'ê³¼ëª©ëª…: ë‚´ìš©...' í˜•íƒœë¥¼ ì„¸íŠ¹ìœ¼ë¡œ ê°€ì •\n",
    "    - 'ë™ì•„ë¦¬í™œë™', 'ììœ¨í™œë™', 'ì§„ë¡œí™œë™', 'ë´‰ì‚¬í™œë™' ë¸”ë¡ì€ ì°½ì²´ë¡œ ì²˜ë¦¬\n",
    "    \"\"\"\n",
    "    sources = []\n",
    "\n",
    "    # 3-1) ì„¸ë¶€ëŠ¥ë ¥íŠ¹ê¸°ì‚¬í•­\n",
    "    pattern = re.compile(\n",
    "        r\"([ê°€-í£A-Za-z0-9\\s]+):\\s*(.+?)(?=\\n[ê°€-í£A-Za-z0-9\\s]+:|\\në™ì•„ë¦¬í™œë™|\\nììœ¨í™œë™|\\nì§„ë¡œí™œë™|\\në´‰ì‚¬í™œë™|\\Z)\",\n",
    "        re.DOTALL\n",
    "    )\n",
    "\n",
    "    for m in pattern.finditer(full_text):\n",
    "        subject = m.group(1).strip()\n",
    "        desc = m.group(2).strip().replace(\"\\n\", \" \")\n",
    "        label = f\"{subject}(ì„¸ë¶€ëŠ¥ë ¥íŠ¹ê¸°ì‚¬í•­)\"\n",
    "        sources.append((label, desc))\n",
    "\n",
    "    # 3-2) ì°½ì²´\n",
    "    blocks = [\"ë™ì•„ë¦¬í™œë™\", \"ììœ¨í™œë™\", \"ì§„ë¡œí™œë™\", \"ë´‰ì‚¬í™œë™\"]\n",
    "    for b in blocks:\n",
    "        bpat = re.compile(\n",
    "            b + r\"\\s*\\n(.+?)(?=\\në™ì•„ë¦¬í™œë™|\\nììœ¨í™œë™|\\nì§„ë¡œí™œë™|\\në´‰ì‚¬í™œë™|\\Z)\",\n",
    "            re.DOTALL\n",
    "        )\n",
    "        for m in bpat.finditer(full_text):\n",
    "            desc = m.group(1).strip().replace(\"\\n\", \" \")\n",
    "            label = b  # ì˜ˆ: \"ì§„ë¡œí™œë™\"\n",
    "            sources.append((label, desc))\n",
    "\n",
    "    return sources\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 4. íƒœë„ì„± ë‚´ìš© ì œê±°\n",
    "##########################################################\n",
    "def filter_out_attitude(sources):\n",
    "    \"\"\"íƒœë„/ì„±ì‹¤ ì¹­ì°¬ ìœ„ì£¼ì˜ ê¸°ë¡ì€ ì§ˆë¬¸ ì¶œì²˜ì—ì„œ ì œì™¸\"\"\"\n",
    "    clean = []\n",
    "    for label, text in sources:\n",
    "        combo = label + \" \" + text\n",
    "        if not any(bad in combo for bad in EXCLUDE_KEYWORDS):\n",
    "            clean.append((label, text))\n",
    "    return clean\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 5. OpenAIë¡œ ì§ˆë¬¸ 50ê°œ ìƒì„± (ìœ í˜• ë¶„ë¥˜ í¬í•¨)\n",
    "##########################################################\n",
    "def generate_questions(full_text, career_by_grade, sources):\n",
    "    \"\"\"\n",
    "    - ì „ê³µ ì í•©ì„± / í™œë™Â·ê²½í—˜ ê¸°ë°˜ / ì¸ì„±Â·ê°€ì¹˜ê´€ ìœ í˜•ìœ¼ë¡œ\n",
    "      ì„ì–´ì„œ ì§ˆë¬¸ 50ê°œ ìƒì„±\n",
    "    - ë¹„ìœ¨ì€ ê³ ì •í•˜ì§€ ì•Šê³ , ìƒê¸°ë¶€ìƒ 'ì¤‘ìš”í•´ ë³´ì´ëŠ” í¬ì¸íŠ¸'ë¥¼ ë” ë§ì´ ë¬»ëŠ”ë‹¤.\n",
    "    \"\"\"\n",
    "\n",
    "    # ìƒê¸°ë¶€ê°€ ë„ˆë¬´ ê¸¸ë©´ ì¼ë¶€ë§Œ ì˜ë¼ì„œ ì „ë‹¬ (í† í° ì ˆì•½ìš©)\n",
    "    truncated_text = full_text[:6000]\n",
    "\n",
    "    # ì¶œì²˜ë„ ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ ëª‡ ê°œë§Œ\n",
    "    max_sources = 30\n",
    "    brief_sources = sources[:max_sources]\n",
    "\n",
    "    sources_str = \"\"\n",
    "    for i, (label, desc) in enumerate(brief_sources, start=1):\n",
    "        sources_str += f\"{i}. ì¶œì²˜: {label}\\n   ë‚´ìš©: {desc[:200]}\\n\"\n",
    "\n",
    "    career_str = \"\"\n",
    "    for g in [1, 2, 3]:\n",
    "        career_str += f\"{g}í•™ë…„ í¬ë§ë¶„ì•¼: {career_by_grade.get(g)}\\n\"\n",
    "\n",
    "    # ğŸ”¥ ì—¬ê¸° system_promptë¥¼ ëŒ€í­ ìˆ˜ì • (ë¹„ìœ¨ ê³ ì • X, ì¤‘ìš” í¬ì¸íŠ¸ ìœ„ì£¼)\n",
    "    system_prompt = \"\"\"\n",
    "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ëŒ€í•™ ì…í•™ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.\n",
    "ì£¼ì–´ì§„ í•™ìƒ ìƒê¸°ë¶€ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒ ì„¸ ê°€ì§€ ìœ í˜•ìœ¼ë¡œ ì¸í„°ë·° ì§ˆë¬¸ì„ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "- ì „ê³µ ì í•©ì„±\n",
    "- í™œë™Â·ê²½í—˜ ê¸°ë°˜\n",
    "- ì¸ì„±Â·ê°€ì¹˜ê´€\n",
    "\n",
    "í•˜ì§€ë§Œ, ê° ìœ í˜•ì˜ ê°œìˆ˜ë¥¼ ì–µì§€ë¡œ ê· ë“±í•˜ê²Œ ë§ì¶”ì§€ ë§ˆì‹­ì‹œì˜¤.\n",
    "ì´ í•™ìƒì„ í‰ê°€í•  ë•Œ \"ì •ë§ë¡œ ì¤‘ìš”í•œ í¬ì¸íŠ¸\"ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì§ˆë¬¸ ë¹„ì¤‘ì„ ì¡°ì ˆí•˜ì‹­ì‹œì˜¤.\n",
    "\n",
    "ìš°ì„ ìˆœìœ„ ì˜ˆì‹œ:\n",
    "1) í•™ë…„ë³„ í¬ë§ë¶„ì•¼ì™€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ” ê³¼ëª©/ì„¸íŠ¹/ì§„ë¡œí™œë™\n",
    "2) í•œ ë²ˆ ì´ìƒ ë°˜ë³µí•´ì„œ ë“±ì¥í•˜ê±°ë‚˜, ë¶„ëŸ‰ì´ ê¸¸ê³  êµ¬ì²´ì ì¸ í™œë™\n",
    "3) ë™ì•„ë¦¬Â·í”„ë¡œì íŠ¸Â·íƒêµ¬ í™œë™ ë“±ì—ì„œ í•™ìƒì´ ì£¼ë„ì ìœ¼ë¡œ ì—­í• ì„ ìˆ˜í–‰í•œ ë¶€ë¶„\n",
    "4) í˜‘ì—…, ê°ˆë“± í•´ê²°, ì±…ì„ê°, ì„ íƒì˜ ê·¼ê±° ë“±ì´ ë“œëŸ¬ë‚˜ëŠ” ì¥ë©´ (ì¸ì„±Â·ê°€ì¹˜ê´€)\n",
    "\n",
    "ê·œì¹™:\n",
    "1) ì§ˆë¬¸ì€ ì´ 50ê°œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "2) ê° ì§ˆë¬¸ì€ ë°˜ë“œì‹œ ì•„ë˜ ì„¸ ìœ í˜• ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.\n",
    "   - ì „ê³µ ì í•©ì„±\n",
    "   - í™œë™Â·ê²½í—˜ ê¸°ë°˜\n",
    "   - ì¸ì„±Â·ê°€ì¹˜ê´€\n",
    "3) ê° ì§ˆë¬¸ë§ˆë‹¤ 'ì¶œì²˜'ë¥¼ ëª…ì‹œí•©ë‹ˆë‹¤.\n",
    "   - ì˜ˆ: '2í•™ë…„ ì¸ê³µì§€ëŠ¥ ìˆ˜í•™(ì„¸ë¶€ëŠ¥ë ¥íŠ¹ê¸°ì‚¬í•­)', '3í•™ë…„ ì§„ë¡œí™œë™', '1í•™ë…„ ë™ì•„ë¦¬í™œë™' ë“±\n",
    "   - ì¶œì²˜ëŠ” ì•„ë˜ ì œê³µëœ sources ëª©ë¡ì„ ì°¸ê³ í•´ ì‘ì„±í•˜ì„¸ìš”.\n",
    "4) í•™ìƒì—ê²Œ 'ë‹µë³€í•˜ë¼'ê³  ìš”êµ¬í•˜ì§€ ë§ê³ , ì§ˆë¬¸ë§Œ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "5) ì§ˆë¬¸ì€ ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ìœ¼ë¡œ, ì‹¤ì œ ë©´ì ‘ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "6) ì „ê³µ ì í•©ì„± ì§ˆë¬¸ì€ 'í¬ë§ë¶„ì•¼ + ê´€ë ¨ ê³¼ëª©/í™œë™'ì— ê°€ì¥ ê°•í•˜ê²Œ ì—°ê²°ëœ ë¶€ë¶„ ìœ„ì£¼ë¡œ ë§Œë“­ë‹ˆë‹¤.\n",
    "7) í™œë™Â·ê²½í—˜ ê¸°ë°˜ ì§ˆë¬¸ì€ ì‹¤ì œ ì„¸íŠ¹/ì°½ì²´ì—ì„œ íŠ¹ì • í™œë™ì„ ì½• ì§‘ì–´, ê³„ê¸°Â·ì—­í• Â·ì–´ë ¤ì›€Â·ê²°ê³¼ë¥¼ ìºë¬»ëŠ” ë°©í–¥ìœ¼ë¡œ ì„¤ê³„í•©ë‹ˆë‹¤.\n",
    "8) ì¸ì„±Â·ê°€ì¹˜ê´€ ì§ˆë¬¸ì€ í•™ìƒì˜ ì„ íƒ ê¸°ì¤€, ì±…ì„ê°, í˜‘ì—… íƒœë„, ê°ˆë“± í•´ê²° ë°©ì‹ì´ ë“œëŸ¬ë‚˜ë„ë¡ ì„¤ê³„í•©ë‹ˆë‹¤.\n",
    "9) ì§ˆë¬¸ ìˆ˜ì˜ ë¹„ìœ¨ì€ ì¤‘ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ë§Œ, ìƒê¸°ë¶€ì—ì„œ ë¹ˆì•½í•œ ë¶€ë¶„ë³´ë‹¤ëŠ”, ì§„ë¡œÂ·ì „ê³µê³¼ ê°•í•˜ê²Œ ì—°ê²°ëœ ë¶€ë¶„ê³¼ ê¹Šê²Œ ì¨ ìˆëŠ” í™œë™ì„ ìš°ì„ ì ìœ¼ë¡œ ë§ì´ ì§ˆë¬¸í•˜ì‹­ì‹œì˜¤.\n",
    "\n",
    "ì¶œë ¥ í˜•ì‹(ì •í™•íˆ ì§€í‚¤ì„¸ìš”):\n",
    "\n",
    "1ë²ˆ\n",
    "- ìœ í˜•: ì „ê³µ ì í•©ì„± / í™œë™Â·ê²½í—˜ ê¸°ë°˜ / ì¸ì„±Â·ê°€ì¹˜ê´€ ì¤‘ í•˜ë‚˜\n",
    "- ì¶œì²˜: (ëª‡ í•™ë…„, ì–´ë–¤ ê³¼ëª© ë˜ëŠ” ì–´ë–¤ í™œë™ì—ì„œ ë‚˜ì˜¨ ì§ˆë¬¸ì¸ì§€)\n",
    "- ì§ˆë¬¸: ~~~?\n",
    "\n",
    "2ë²ˆ\n",
    "- ìœ í˜•: ...\n",
    "- ì¶œì²˜: ...\n",
    "- ì§ˆë¬¸: ...?\n",
    "\n",
    "...\n",
    "\n",
    "50ë²ˆ\n",
    "- ìœ í˜•: ...\n",
    "- ì¶œì²˜: ...\n",
    "- ì§ˆë¬¸: ...?\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "[í•™ìƒ ìƒê¸°ë¶€ í†µí•© í…ìŠ¤íŠ¸ ì¼ë¶€]\n",
    "{truncated_text}\n",
    "\n",
    "[í•™ë…„ë³„ í¬ë§ë¶„ì•¼]\n",
    "{career_str}\n",
    "\n",
    "[ì§ˆë¬¸ ì„¤ê³„ì— ì°¸ê³ í•  ì£¼ìš” ì¶œì²˜ ëª©ë¡]\n",
    "{sources_str}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì´ 50ê°œì˜ ë©´ì ‘ ì§ˆë¬¸ì„ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=4000\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 6. ìœ í˜•ë³„ ì§ˆë¬¸ ê°œìˆ˜ ì„¸ê¸°\n",
    "##########################################################\n",
    "def count_question_types(questions_block: str):\n",
    "    \"\"\"\n",
    "    ìƒì„±ëœ ì§ˆë¬¸ ë¸”ë¡ í…ìŠ¤íŠ¸ì—ì„œ\n",
    "    '- ìœ í˜•: ...' ì¤„ì„ ì°¾ì•„ ìœ í˜•ë³„ ê°œìˆ˜ë¥¼ ì„¼ë‹¤.\n",
    "    \"\"\"\n",
    "    type_counts = {\n",
    "        \"ì „ê³µ ì í•©ì„±\": 0,\n",
    "        \"í™œë™Â·ê²½í—˜ ê¸°ë°˜\": 0,\n",
    "        \"ì¸ì„±Â·ê°€ì¹˜ê´€\": 0,\n",
    "        \"ê¸°íƒ€\": 0\n",
    "    }\n",
    "\n",
    "    matches = re.findall(r\"-\\s*ìœ í˜•:\\s*([^\\n]+)\", questions_block)\n",
    "\n",
    "    for t in matches:\n",
    "        t_clean = t.strip()\n",
    "        if \"ì „ê³µ\" in t_clean:\n",
    "            type_counts[\"ì „ê³µ ì í•©ì„±\"] += 1\n",
    "        elif \"í™œë™\" in t_clean or \"ê²½í—˜\" in t_clean:\n",
    "            type_counts[\"í™œë™Â·ê²½í—˜ ê¸°ë°˜\"] += 1\n",
    "        elif \"ì¸ì„±\" in t_clean or \"ê°€ì¹˜ê´€\" in t_clean:\n",
    "            type_counts[\"ì¸ì„±Â·ê°€ì¹˜ê´€\"] += 1\n",
    "        else:\n",
    "            type_counts[\"ê¸°íƒ€\"] += 1\n",
    "\n",
    "    return type_counts\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 7. ë©”ì¸ ì‹¤í–‰\n",
    "##########################################################\n",
    "def main():\n",
    "    with open(\"wnskadud_structured (1).json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    full_text = get_full_text(data)\n",
    "    career_by_grade = extract_career_by_grade(full_text)\n",
    "    sources = extract_sources(full_text)\n",
    "    sources = filter_out_attitude(sources)\n",
    "\n",
    "    print(\"=== í¬ë§ë¶„ì•¼ ì¸ì‹ ê²°ê³¼ ===\")\n",
    "    for g in [1, 2, 3]:\n",
    "        print(f\"{g}í•™ë…„ â†’ {career_by_grade.get(g)}\")\n",
    "    print(\"=========================\\n\")\n",
    "\n",
    "    if not sources:\n",
    "        print(\"âš  ì§ˆë¬¸ ì¶œì²˜ë¡œ ì‚¬ìš©í•  ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. JSON ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        return\n",
    "\n",
    "    questions_block = generate_questions(full_text, career_by_grade, sources)\n",
    "\n",
    "    print(\"\\n===== ìƒì„±ëœ ë©´ì ‘ ì§ˆë¬¸ 50ê°œ =====\\n\")\n",
    "    print(questions_block)\n",
    "    print(\"\\n================================\\n\")\n",
    "\n",
    "    # ìœ í˜•ë³„ ê°œìˆ˜ ì„¸ê¸°\n",
    "    type_counts = count_question_types(questions_block)\n",
    "\n",
    "    print(\"=== ìœ í˜•ë³„ ì§ˆë¬¸ ê°œìˆ˜ ===\")\n",
    "    print(f\"- ì „ê³µ ì í•©ì„±: {type_counts['ì „ê³µ ì í•©ì„±']}ê°œ\")\n",
    "    print(f\"- í™œë™Â·ê²½í—˜ ê¸°ë°˜: {type_counts['í™œë™Â·ê²½í—˜ ê¸°ë°˜']}ê°œ\")\n",
    "    print(f\"- ì¸ì„±Â·ê°€ì¹˜ê´€: {type_counts['ì¸ì„±Â·ê°€ì¹˜ê´€']}ê°œ\")\n",
    "    print(f\"- ê¸°íƒ€(ë¶„ë¥˜ ë¶ˆëª…): {type_counts['ê¸°íƒ€']}ê°œ\")\n",
    "    print(\"========================\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
