{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4c432-294c-48a4-9ed9-38e7ab883daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "# ===== í™˜ê²½ ì„¤ì • =====\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai.Client()\n",
    "\n",
    "TOTAL_QUESTIONS = 3\n",
    "\n",
    "SKIP_KEYWORDS = [\n",
    "    \"ë‹¤ìŒ ì§ˆë¬¸\", \"ë‹¤ìŒì§ˆë¬¸\", \"ìŠ¤í‚µ\", \"skip\", \"pass\", \"next\",\n",
    "    \"next question\", \"ë„˜ì–´ê°€ê¸°\", \"ë„˜ì–´ê°€ì\", \"ë„˜ì–´ê°ˆê²Œìš”\"\n",
    "]\n",
    "\n",
    "# íƒœë„/ëª¨ë²”/ì„±ì‹¤ ì¹­ì°¬ë§Œ ì œê±°\n",
    "EXCLUDE_KEYWORDS = [\n",
    "    \"ì„±ì‹¤\", \"ì„±ì‹¤í•¨\", \"ì„±ì‹¤í•˜ê²Œ\", \"ëª¨ë²”\", \"ëª¨ë²”ì ì¸\",\n",
    "    \"íƒœë„\", \"íƒœë„ê°€\", \"ìì„¸ê°€ ì¢‹\", \"ì •ì„±ì„ ë‹¤í•´\",\n",
    "    \"ë°œí‘œí•œ ëª¨ìŠµì´ ë³´ê¸° ì¢‹ì•˜\", \"ë°œí‘œë¥¼ ì˜í•¨\", \"ë°œí‘œë¥¼ ì˜ í•˜\",\n",
    "    \"ì°¸ì—¬ë„ê°€ ë†’\", \"ì—´ì‹¬íˆ ì°¸ì—¬\", \"ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬\",\n",
    "    \"ì¹œêµ¬ë“¤ê³¼ ì˜ ì§€ë‚´\", \"ë´‰ì‚¬ì •ì‹ ì´ íˆ¬ì² \", \"ì˜ˆì˜ë°”ë¥¸ íƒœë„\"\n",
    "]\n",
    "\n",
    "# í¬ë§ ë¶„ì•¼ ë§¤í•‘\n",
    "CAREER_SUBJECT_MAP = {\n",
    "    \"ê³µí•™\": [\"ìˆ˜í•™\", \"ê¸°í•˜\", \"ë¯¸ì \", \"ë¯¸ì ë¶„\", \"ê³¼í•™\", \"ë¬¼ë¦¬\",\n",
    "           \"ìœµí•©ê³¼í•™\", \"ì •ë³´\", \"í”„ë¡œê·¸ë˜ë°\", \"ê³µí•™\", \"ì¸ê³µì§€ëŠ¥ ìˆ˜í•™\"],\n",
    "    \"ìì—°\": [\"ìƒëª…\", \"ìƒëª…ê³¼í•™\", \"í™”í•™\", \"ì§€êµ¬\", \"ì§€êµ¬ê³¼í•™\", \"ë¬¼ë¦¬\", \"ê³¼í•™\"],\n",
    "    \"ì˜í•™\": [\"ìƒëª…\", \"ìƒëª…ê³¼í•™\", \"í™”í•™\", \"ë³´ê±´\", \"ì˜í•™\"],\n",
    "    \"ì»´í“¨í„°\": [\"ì •ë³´\", \"í”„ë¡œê·¸ë˜ë°\", \"AI\", \"ë°ì´í„°\", \"ìˆ˜í•™\",\n",
    "            \"ê¸°í•˜\", \"ë¯¸ì ë¶„\", \"ì¸ê³µì§€ëŠ¥ ìˆ˜í•™\", \"ì»´í“¨í„°ê³µí•™\"],\n",
    "    \"ì†Œí”„íŠ¸ì›¨ì–´\": [\"ì •ë³´\", \"í”„ë¡œê·¸ë˜ë°\", \"AI\", \"ì»´í“¨í„°\", \"ìˆ˜í•™\"],\n",
    "    \"AI\": [\"ì •ë³´\", \"í”„ë¡œê·¸ë˜ë°\", \"AI\", \"ìœµí•©ê³¼í•™\", \"ìˆ˜í•™\", \"ì¸ê³µì§€ëŠ¥ ìˆ˜í•™\"],\n",
    "    \"ìƒê²½\": [\"ê²½ì œ\", \"ì‚¬íšŒ\", \"ì •ì¹˜\", \"ìˆ˜í•™\", \"í™•ë¥ ê³¼í†µê³„\"],\n",
    "    \"ê²½ì˜\": [\"ê²½ì˜\", \"ê²½ì œ\", \"ì‚¬íšŒ\", \"ìˆ˜í•™\"],\n",
    "    \"ì¸ë¬¸\": [\"êµ­ì–´\", \"ë¬¸í•™\", \"ë…ì„œ\", \"ì‚¬íšŒ\", \"ìœ¤ë¦¬\", \"ì² í•™\"],\n",
    "    \"êµìœ¡\": [\"êµìœ¡\", \"ì‹¬ë¦¬\", \"êµ­ì–´\", \"ì‚¬íšŒ\"]\n",
    "}\n",
    "\n",
    "##########################################################\n",
    "# 1. ì „ì²´ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°\n",
    "##########################################################\n",
    "def get_full_text(student_data):\n",
    "    records = student_data.get(\"academic_records\", [])\n",
    "    if isinstance(records, list):\n",
    "        full = \"\\n\".join(str(x) for x in records)\n",
    "    else:\n",
    "        full = str(records)\n",
    "\n",
    "    reading = student_data.get(\"reading\", \"\")\n",
    "    if reading:\n",
    "        full += \"\\n\" + str(reading)\n",
    "\n",
    "    return full\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 2. í¬ë§ë¶„ì•¼ â†’ í•™ë…„ë³„ ìë™ ë°°ì •\n",
    "##########################################################\n",
    "def infer_career_from_text(full_text): # fallback\n",
    "    scores = {k: 0 for k in CAREER_SUBJECT_MAP}\n",
    "\n",
    "    for career, keywords in CAREER_SUBJECT_MAP.items():\n",
    "        for kw in keywords:\n",
    "            if kw in full_text:\n",
    "                scores[career] += 1\n",
    "\n",
    "    best = max(scores, key=scores.get)\n",
    "    return best if scores[best] > 0 else None\n",
    "\n",
    "def extract_career_by_grade(full_text):\n",
    "    pattern = re.compile(\n",
    "        r\"(?:í¬ë§|ì§„ë¡œ)\\s*(?:ë¶„ì•¼|í¬ë§|ê³„íš)?\\s*[:ï¼š\\-]?\\s*([^\\n]+)\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    matches = re.findall(r\"í¬ë§\\s*ë¶„ì•¼\\s*([^\\n]+)\", full_text)\n",
    "\n",
    "    grade_raw = {1: None, 2: None, 3: None}\n",
    "    for idx, raw in enumerate(matches[:3], start=1):\n",
    "        cleaned = raw.replace(\"ë¶„ì•¼\", \"\").replace(\"ê³„ì—´\", \"\").strip()\n",
    "        grade_raw[idx] = cleaned\n",
    "\n",
    "    def normalize(field):\n",
    "        if not field:\n",
    "            return \"\"\n",
    "        if \"ì»´í“¨í„°\" in field or \"ì†Œí”„íŠ¸ì›¨ì–´\" in field:\n",
    "            return \"ì»´í“¨í„°\"\n",
    "        if \"ai\" in field.lower():\n",
    "            return \"AI\"\n",
    "        if \"ê³µí•™\" in field:\n",
    "            return \"ê³µí•™\"\n",
    "        if \"ìì—°\" in field:\n",
    "            return \"ìì—°\"\n",
    "        if \"ì˜í•™\" in field:\n",
    "            return \"ì˜í•™\"\n",
    "        if \"ê²½ì˜\" in field:\n",
    "            return \"ê²½ì˜\"\n",
    "        if \"ìƒê²½\" in field:\n",
    "            return \"ìƒê²½\"\n",
    "        if \"ì¸ë¬¸\" in field:\n",
    "            return \"ì¸ë¬¸\"\n",
    "        if \"êµìœ¡\" in field:\n",
    "            return \"êµìœ¡\"\n",
    "        return field\n",
    "\n",
    "    grade_norm = {g: normalize(v) for g, v in grade_raw.items()}\n",
    "\n",
    "    for g in grade_norm:\n",
    "        if not grade_norm[g]:\n",
    "            inferred = infer_career_from_text(full_text)\n",
    "            grade_norm[g] = inferred\n",
    "            grade_raw[g] = inferred\n",
    "\n",
    "    return grade_raw, grade_norm\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 3. ì„¸íŠ¹/ì°½ì²´ ì¶œì²˜ ìë™ ì¶”ì¶œ\n",
    "##########################################################\n",
    "def extract_sources(full_text):\n",
    "    sources = []\n",
    "\n",
    "    # 3-1) ì„¸ë¶€ëŠ¥ë ¥íŠ¹ê¸°ì‚¬í•­\n",
    "    pattern = re.compile(\n",
    "        r\"([ê°€-í£A-Za-z0-9\\s]+):\\s*(.+?)(?=\\n[ê°€-í£A-Za-z0-9\\s]+:|\\në™ì•„ë¦¬í™œë™|\\nììœ¨í™œë™|\\nì§„ë¡œí™œë™|\\në´‰ì‚¬í™œë™|\\Z)\",\n",
    "        re.DOTALL\n",
    "    )\n",
    "\n",
    "    for m in pattern.finditer(full_text):\n",
    "        subject = m.group(1).strip()\n",
    "        desc = m.group(2).strip().replace(\"\\n\", \" \")[:250]\n",
    "        label = f\"{subject}(ì„¸ë¶€ëŠ¥ë ¥íŠ¹ê¸°ì‚¬í•­)\"\n",
    "        sources.append((label, desc))\n",
    "\n",
    "    # 3-2) ì°½ì²´\n",
    "    blocks = [\"ë™ì•„ë¦¬í™œë™\", \"ììœ¨í™œë™\", \"ì§„ë¡œí™œë™\", \"ë´‰ì‚¬í™œë™\"]\n",
    "    for b in blocks:\n",
    "        bpat = re.compile(\n",
    "            b + r\"\\s*\\n(.+?)(?=\\në™ì•„ë¦¬í™œë™|\\nììœ¨í™œë™|\\nì§„ë¡œí™œë™|\\në´‰ì‚¬í™œë™|\\Z)\",\n",
    "            re.DOTALL\n",
    "        )\n",
    "        for m in bpat.finditer(full_text):\n",
    "            desc = m.group(1).strip().replace(\"\\n\", \" \")[:250]\n",
    "            sources.append((b, desc))\n",
    "\n",
    "    return sources\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 4. íƒœë„ì„± ë‚´ìš© ì œê±°\n",
    "##########################################################\n",
    "def filter_out_attitude(sources):\n",
    "    clean = []\n",
    "    for label, text in sources:\n",
    "        combo = label + \" \" + text\n",
    "        if not any(bad in combo for bad in EXCLUDE_KEYWORDS):\n",
    "            clean.append((label, text))\n",
    "    return clean\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 5. label â†’ ê³¼ëª©ëª…/í™œë™ì¢…ë¥˜ ë¶„ë¦¬\n",
    "##########################################################\n",
    "def split_label(label):\n",
    "    if \"(\" in label:\n",
    "        subject = label.split(\"(\")[0]\n",
    "        activity = label[label.find(\"(\")+1:-1]\n",
    "    else:\n",
    "        subject = label\n",
    "        activity = \"ì°½ì²´í™œë™\"\n",
    "\n",
    "    return subject.strip(), activity.strip()\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 6. ë©”ì¸ ë¡œì§\n",
    "##########################################################\n",
    "def start_ai_interview(student_data):\n",
    "    full_text = get_full_text(student_data)\n",
    "\n",
    "    career_raw, career_norm = extract_career_by_grade(full_text)\n",
    "\n",
    "    print(\"\\n=== í¬ë§ë¶„ì•¼ ì¸ì‹ ê²°ê³¼ ===\")\n",
    "    for g in [1,2,3]:\n",
    "        print(f\"{g}í•™ë…„ â†’ {career_raw.get(g)} (í‚¤ì›Œë“œ: {career_norm.get(g)})\")\n",
    "    print(\"==========================\\n\")\n",
    "\n",
    "    sources = extract_sources(full_text)\n",
    "    sources = filter_out_attitude(sources)\n",
    "\n",
    "    if not sources:\n",
    "        print(\"âš  ì¶œì²˜ ì—†ìŒ. JSON êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        return\n",
    "\n",
    "    system_prompt = '''\n",
    "ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ ìµœìƒìœ„ê¶Œ ê³µëŒ€ ë©´ì ‘ê´€ì´ë‹¤.\n",
    "ë§¤ìš° ëƒ‰ì •í•˜ê³  ë‚ ì¹´ë¡­ê²Œ í‰ê°€í•˜ë©° ìƒê¸°ë¶€ì™€ ë¬´ê´€í•œ ë‹µë³€ì€ ëª¨ë‘ í˜¹í‰í•˜ë¼.\n",
    "\n",
    "[í”¼ë“œë°± í˜•ì‹]\n",
    "- ìƒê¸°ë¶€ ì—°ê´€ì„±: X/40\n",
    "- ë…¼ë¦¬ì„±: X/30\n",
    "- êµ¬ì²´ì„±: X/30\n",
    "- ì´í‰: í•œ ë¬¸ì¥ìœ¼ë¡œ ë§¤ìš° ëƒ‰ì •í•˜ê²Œ\n",
    "- ë¶€ì¡±í•œ ì : 2~3ì¤„\n",
    "- ë°”ëŒì§í•œ ë‹µë³€ ë°©í–¥: 2~3ì¤„\n",
    "[ì ìˆ˜]\n",
    "XX/100ì \n",
    "\n",
    "ì ìˆ˜ < 70ì ì´ë©´ ë°˜ë“œì‹œ [ë‹¤ì‹œ ë‹µë³€ ìš”ì²­]ì„ ë¶™ì¸ë‹¤.\n",
    "'''\n",
    "\n",
    "    question_num = 1\n",
    "\n",
    "    while question_num <= TOTAL_QUESTIONS:\n",
    "\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "\n",
    "        selected_grade = random.choice([1, 2, 3])\n",
    "        selected_career_raw = career_raw.get(selected_grade)\n",
    "        selected_career_norm = career_norm.get(selected_grade)\n",
    "\n",
    "        allowed_keywords = CAREER_SUBJECT_MAP.get(selected_career_norm, [])\n",
    "        grade_sources = [\n",
    "            s for s in sources if any(k in (s[0] + s[1]) for k in allowed_keywords)\n",
    "        ]\n",
    "        if not grade_sources:\n",
    "            grade_sources = sources\n",
    "\n",
    "        label, text = random.choice(grade_sources)\n",
    "        subject_name, activity_type = split_label(label)\n",
    "\n",
    "        is_last = (question_num == TOTAL_QUESTIONS)\n",
    "\n",
    "        user_prompt = f'''\n",
    "ë‹¤ìŒ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ {\"[ë§ˆì§€ë§‰ ì§ˆë¬¸]\" if is_last else \"[ì§ˆë¬¸]\"}ì„ ìƒì„±í•˜ë¼.\n",
    "\n",
    "ì¶œì²˜ í•™ë…„: {selected_grade}í•™ë…„\n",
    "ê³¼ëª©ëª…: {subject_name}\n",
    "í™œë™ì¢…ë¥˜: {activity_type}\n",
    "ì¶œì²˜ ì „ë¬¸: {label}\n",
    "í•µì‹¬ ë‚´ìš©: {text}\n",
    "\n",
    "í•´ë‹¹ í•™ë…„ í¬ë§ë¶„ì•¼: {selected_career_raw} (í‚¤ì›Œë“œ: {selected_career_norm})\n",
    "\n",
    "í˜•ì‹:\n",
    "{\"[ë§ˆì§€ë§‰ ì§ˆë¬¸]\" if is_last else \"[ì§ˆë¬¸]\"}\n",
    "ì¶œì²˜: {selected_grade}í•™ë…„ Â· {subject_name} ({activity_type})\n",
    "í¬ë§ë¶„ì•¼({selected_grade}í•™ë…„): {selected_career_raw}\n",
    "í•µì‹¬ ë‚´ìš©: {text}\n",
    "ì§ˆë¬¸:\n",
    "'''\n",
    "        messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            max_tokens=600\n",
    "        )\n",
    "        qtext = resp.choices[0].message.content\n",
    "        print(\"\\n\" + qtext)\n",
    "        messages.append({\"role\": \"assistant\", \"content\": qtext})\n",
    "\n",
    "        answer = input(\"\\n[í•™ìƒ ë‹µë³€ ë˜ëŠ” 'ë‹¤ìŒ ì§ˆë¬¸'] > \").strip()\n",
    "\n",
    "        if answer == \"\":\n",
    "            print(\"\\nâš  ë‹µë³€ì„ ì…ë ¥í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê°™ì€ ì§ˆë¬¸ì„ ìœ ì§€í•©ë‹ˆë‹¤.\\n\")\n",
    "            continue\n",
    "\n",
    "        if any(k in answer.lower() for k in SKIP_KEYWORDS):\n",
    "            print(\"\\n[ì•ˆë‚´] ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.\\n\")\n",
    "            question_num += 1\n",
    "            continue\n",
    "\n",
    "        if answer.lower() in (\"exit\", \"quit\"):\n",
    "            print(\"ë©´ì ‘ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "\n",
    "        eval_prompt = f'''\n",
    "[í•™ìƒ ë‹µë³€]\n",
    "{answer}\n",
    "\n",
    "ì¶œì²˜ í•™ë…„: {selected_grade}í•™ë…„\n",
    "ê³¼ëª©ëª…: {subject_name}\n",
    "í™œë™ì¢…ë¥˜: {activity_type}\n",
    "ì¶œì²˜ ì „ë¬¸: {label}\n",
    "í•µì‹¬ ë‚´ìš©: {text}\n",
    "í¬ë§ë¶„ì•¼({selected_grade}í•™ë…„): {selected_career_raw}\n",
    "\n",
    "A ëª¨ë“œë¡œ ë§¤ìš° ë‚ ì¹´ë¡­ê²Œ í‰ê°€í•˜ë¼.\n",
    "'''\n",
    "\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "        \n",
    "        messages.append({\"role\": \"user\", \"content\": eval_prompt})\n",
    "\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            max_tokens=900\n",
    "        )\n",
    "        eval_text = resp.choices[0].message.content\n",
    "\n",
    "        # === [ë‹¤ì‹œ ë‹µë³€ ìš”ì²­] ë¬¸êµ¬ëŠ” í•™ìƒì—ê²Œ ìˆ¨ê¹€ ===\n",
    "        eval_text_clean = eval_text.replace(\"[ë‹¤ì‹œ ë‹µë³€ ìš”ì²­]\", \"\").strip()\n",
    "        print(\"\\n\" + eval_text_clean)\n",
    "\n",
    "        messages.append({\"role\": \"assistant\", \"content\": eval_text})\n",
    "\n",
    "        score = None\n",
    "        m = re.search(r\"(\\d+)\\s*/\\s*100\", eval_text)\n",
    "        if m:\n",
    "            score = int(m.group(1))\n",
    "\n",
    "        if (score is not None and score < 70):\n",
    "            print(\"\\nâš  70ì  ë¯¸ë§Œì…ë‹ˆë‹¤. ê°™ì€ ì§ˆë¬¸ì— ë‹¤ì‹œ ë‹µë³€í•˜ì„¸ìš”.\\n\")\n",
    "            continue\n",
    "\n",
    "        question_num += 1\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 7. ìƒí™œê¸°ë¡ë¶€ TXT íŒŒì¼ì„ ì½”ë“œê°€ ì½ì„ ìˆ˜ ìˆëŠ” ë°ì´í„° êµ¬ì¡°ë¡œ ë³€í™˜\n",
    "##########################################################\n",
    "def load_student_txt(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read().strip()\n",
    "\n",
    "    # ì´ë¦„ ì¶”ì¶œ (ì—†ì–´ë„ ë™ì‘)\n",
    "    name_match = re.search(r\"ì´ë¦„\\s*[:ï¼š]\\s*(.+)\", text)\n",
    "    name = name_match.group(1).strip() if name_match else \"ì´ë¦„ ë¯¸ìƒ\"\n",
    "\n",
    "    return {\n",
    "        \"student_info\": {\n",
    "            \"name\": name\n",
    "        },\n",
    "        \"academic_records\": text,  # ë¬¸ìì—´ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "        \"reading\": \"\"\n",
    "    }\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 8. ì‹¤í–‰\n",
    "##########################################################\n",
    "RECORDINGS_DIR = \"recordings_lite\"\n",
    "TARGET_FILE = \"202315060_3í•™ë…„_íœ´ë¨¼AIê³µí•™ì „ê³µ_ì„œí˜„ìŠ¹_ì •ì‹œ_censored.txt\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    TARGET_PATH = os.path.join(RECORDINGS_DIR, TARGET_FILE)  # ğŸ‘ˆ ì—¬ê¸°ë§Œ ë°”ê¾¸ë©´ ë¨\n",
    "\n",
    "    if not os.path.exists(TARGET_PATH):\n",
    "        print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {TARGET_PATH}\")\n",
    "        exit()\n",
    "\n",
    "    data = load_student_txt(TARGET_PATH)\n",
    "    \n",
    "    print(\"ğŸ“„ ì‚¬ìš© íŒŒì¼:\", TARGET_PATH)\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    start_ai_interview(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
