{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03e38a58-fbdd-4838-80f5-7c47c00ecc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 희망분야 인식 결과 ===\n",
      "1학년 → 공학 (키워드: 공학)\n",
      "2학년 → 컴퓨터공학 (키워드: 컴퓨터)\n",
      "3학년 → 컴퓨터 공학 (키워드: 컴퓨터)\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-ieq3S40n7w9a3M3JXtI33y8c on tokens per min (TPM): Limit 100000, Used 99782, Requested 529. Please try again in 2h14m21.12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 307\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mwnskadud_structured (1).json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    305\u001b[39m     data = json.load(f)\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m \u001b[43mstart_ai_interview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 236\u001b[39m, in \u001b[36mstart_ai_interview\u001b[39m\u001b[34m(student_data)\u001b[39m\n\u001b[32m    216\u001b[39m         user_prompt = \u001b[33mf\u001b[39m\u001b[33m'''\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[33m다음 정보를 기반으로 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m[마지막 질문]\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mis_last\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[질문]\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m을 생성하라.\u001b[39m\n\u001b[32m    218\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    232\u001b[39m \u001b[33m질문:\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[33m'''\u001b[39m\n\u001b[32m    234\u001b[39m         messages.append({\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: user_prompt})\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m         resp = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m600\u001b[39;49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m         qtext = resp.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m    242\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + qtext)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_utils\\_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1189\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1142\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1144\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1186\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1187\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1188\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-ieq3S40n7w9a3M3JXtI33y8c on tokens per min (TPM): Limit 100000, Used 99782, Requested 529. Please try again in 2h14m21.12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "# ===== 환경 설정 =====\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai.Client()\n",
    "\n",
    "TOTAL_QUESTIONS = 6\n",
    "\n",
    "SKIP_KEYWORDS = [\n",
    "    \"다음 질문\", \"다음질문\", \"스킵\", \"skip\", \"pass\", \"next\",\n",
    "    \"next question\", \"넘어가기\", \"넘어가자\", \"넘어갈게요\"\n",
    "]\n",
    "\n",
    "# 태도/모범/성실 칭찬만 제거\n",
    "EXCLUDE_KEYWORDS = [\n",
    "    \"성실\", \"성실함\", \"성실하게\", \"모범\", \"모범적인\",\n",
    "    \"태도\", \"태도가\", \"자세가 좋\", \"정성을 다해\",\n",
    "    \"발표한 모습이 보기 좋았\", \"발표를 잘함\", \"발표를 잘 하\",\n",
    "    \"참여도가 높\", \"열심히 참여\", \"적극적으로 참여\",\n",
    "    \"친구들과 잘 지내\", \"봉사정신이 투철\", \"예의바른 태도\"\n",
    "]\n",
    "\n",
    "# 희망 분야 매핑\n",
    "CAREER_SUBJECT_MAP = {\n",
    "    \"공학\": [\"수학\", \"기하\", \"미적\", \"미적분\", \"과학\", \"물리\",\n",
    "           \"융합과학\", \"정보\", \"프로그래밍\", \"공학\", \"인공지능 수학\"],\n",
    "    \"자연\": [\"생명\", \"생명과학\", \"화학\", \"지구\", \"지구과학\", \"물리\", \"과학\"],\n",
    "    \"의학\": [\"생명\", \"생명과학\", \"화학\", \"보건\", \"의학\"],\n",
    "    \"컴퓨터\": [\"정보\", \"프로그래밍\", \"AI\", \"데이터\", \"수학\",\n",
    "            \"기하\", \"미적분\", \"인공지능 수학\", \"컴퓨터공학\"],\n",
    "    \"소프트웨어\": [\"정보\", \"프로그래밍\", \"AI\", \"컴퓨터\", \"수학\"],\n",
    "    \"AI\": [\"정보\", \"프로그래밍\", \"AI\", \"융합과학\", \"수학\", \"인공지능 수학\"],\n",
    "    \"상경\": [\"경제\", \"사회\", \"정치\", \"수학\", \"확률과통계\"],\n",
    "    \"경영\": [\"경영\", \"경제\", \"사회\", \"수학\"],\n",
    "    \"인문\": [\"국어\", \"문학\", \"독서\", \"사회\", \"윤리\", \"철학\"],\n",
    "    \"교육\": [\"교육\", \"심리\", \"국어\", \"사회\"]\n",
    "}\n",
    "\n",
    "##########################################################\n",
    "# 1. 전체 텍스트 합치기\n",
    "##########################################################\n",
    "def get_full_text(student_data):\n",
    "    records = student_data.get(\"academic_records\", [])\n",
    "    if isinstance(records, list):\n",
    "        full = \"\\n\".join(str(x) for x in records)\n",
    "    else:\n",
    "        full = str(records)\n",
    "\n",
    "    reading = student_data.get(\"reading\", \"\")\n",
    "    if reading:\n",
    "        full += \"\\n\" + str(reading)\n",
    "\n",
    "    return full\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 2. 희망분야 → 학년별 자동 배정\n",
    "##########################################################\n",
    "def extract_career_by_grade(full_text):\n",
    "    matches = re.findall(r\"희망\\s*분야\\s*([^\\n]+)\", full_text)\n",
    "\n",
    "    grade_raw = {1: None, 2: None, 3: None}\n",
    "    for idx, raw in enumerate(matches[:3], start=1):\n",
    "        cleaned = raw.replace(\"분야\", \"\").replace(\"계열\", \"\").strip()\n",
    "        grade_raw[idx] = cleaned\n",
    "\n",
    "    def normalize(field):\n",
    "        if not field:\n",
    "            return \"\"\n",
    "        if \"컴퓨터\" in field or \"소프트웨어\" in field:\n",
    "            return \"컴퓨터\"\n",
    "        if \"ai\" in field.lower():\n",
    "            return \"AI\"\n",
    "        if \"공학\" in field:\n",
    "            return \"공학\"\n",
    "        if \"자연\" in field:\n",
    "            return \"자연\"\n",
    "        if \"의학\" in field:\n",
    "            return \"의학\"\n",
    "        if \"경영\" in field:\n",
    "            return \"경영\"\n",
    "        if \"상경\" in field:\n",
    "            return \"상경\"\n",
    "        if \"인문\" in field:\n",
    "            return \"인문\"\n",
    "        if \"교육\" in field:\n",
    "            return \"교육\"\n",
    "        return field\n",
    "\n",
    "    grade_norm = {g: normalize(v) for g, v in grade_raw.items()}\n",
    "    return grade_raw, grade_norm\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 3. 세특/창체 출처 자동 추출\n",
    "##########################################################\n",
    "def extract_sources(full_text):\n",
    "    sources = []\n",
    "\n",
    "    # 3-1) 세부능력특기사항\n",
    "    pattern = re.compile(\n",
    "        r\"([가-힣A-Za-z0-9\\s]+):\\s*(.+?)(?=\\n[가-힣A-Za-z0-9\\s]+:|\\n동아리활동|\\n자율활동|\\n진로활동|\\n봉사활동|\\Z)\",\n",
    "        re.DOTALL\n",
    "    )\n",
    "\n",
    "    for m in pattern.finditer(full_text):\n",
    "        subject = m.group(1).strip()\n",
    "        desc = m.group(2).strip().replace(\"\\n\", \" \")[:250]\n",
    "        label = f\"{subject}(세부능력특기사항)\"\n",
    "        sources.append((label, desc))\n",
    "\n",
    "    # 3-2) 창체\n",
    "    blocks = [\"동아리활동\", \"자율활동\", \"진로활동\", \"봉사활동\"]\n",
    "    for b in blocks:\n",
    "        bpat = re.compile(\n",
    "            b + r\"\\s*\\n(.+?)(?=\\n동아리활동|\\n자율활동|\\n진로활동|\\n봉사활동|\\Z)\",\n",
    "            re.DOTALL\n",
    "        )\n",
    "        for m in bpat.finditer(full_text):\n",
    "            desc = m.group(1).strip().replace(\"\\n\", \" \")[:250]\n",
    "            sources.append((b, desc))\n",
    "\n",
    "    return sources\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 4. 태도성 내용 제거\n",
    "##########################################################\n",
    "def filter_out_attitude(sources):\n",
    "    clean = []\n",
    "    for label, text in sources:\n",
    "        combo = label + \" \" + text\n",
    "        if not any(bad in combo for bad in EXCLUDE_KEYWORDS):\n",
    "            clean.append((label, text))\n",
    "    return clean\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 5. label → 과목명/활동종류 분리\n",
    "##########################################################\n",
    "def split_label(label):\n",
    "    if \"(\" in label:\n",
    "        subject = label.split(\"(\")[0]\n",
    "        activity = label[label.find(\"(\")+1:-1]\n",
    "    else:\n",
    "        subject = label\n",
    "        activity = \"창체활동\"\n",
    "\n",
    "    return subject.strip(), activity.strip()\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 6. 메인 로직\n",
    "##########################################################\n",
    "def start_ai_interview(student_data):\n",
    "    full_text = get_full_text(student_data)\n",
    "\n",
    "    career_raw, career_norm = extract_career_by_grade(full_text)\n",
    "\n",
    "    print(\"\\n=== 희망분야 인식 결과 ===\")\n",
    "    for g in [1,2,3]:\n",
    "        print(f\"{g}학년 → {career_raw.get(g)} (키워드: {career_norm.get(g)})\")\n",
    "    print(\"==========================\\n\")\n",
    "\n",
    "    sources = extract_sources(full_text)\n",
    "    sources = filter_out_attitude(sources)\n",
    "\n",
    "    if not sources:\n",
    "        print(\"⚠ 출처 없음. JSON 구조를 확인하세요.\")\n",
    "        return\n",
    "\n",
    "    system_prompt = '''\n",
    "너는 대한민국 최상위권 공대 면접관이다.\n",
    "매우 냉정하고 날카롭게 평가하며 생기부와 무관한 답변은 모두 혹평하라.\n",
    "\n",
    "[피드백 형식]\n",
    "- 생기부 연관성: X/40\n",
    "- 논리성: X/30\n",
    "- 구체성: X/30\n",
    "- 총평: 한 문장으로 매우 냉정하게\n",
    "- 부족한 점: 2~3줄\n",
    "- 바람직한 답변 방향: 2~3줄\n",
    "[점수]\n",
    "XX/100점\n",
    "\n",
    "점수 < 70점이면 반드시 [다시 답변 요청]을 붙인다.\n",
    "'''\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "\n",
    "    question_num = 1\n",
    "\n",
    "    while question_num <= TOTAL_QUESTIONS:\n",
    "\n",
    "        selected_grade = random.choice([1, 2, 3])\n",
    "        selected_career_raw = career_raw.get(selected_grade)\n",
    "        selected_career_norm = career_norm.get(selected_grade)\n",
    "\n",
    "        allowed_keywords = CAREER_SUBJECT_MAP.get(selected_career_norm, [])\n",
    "        grade_sources = [\n",
    "            s for s in sources if any(k in (s[0] + s[1]) for k in allowed_keywords)\n",
    "        ]\n",
    "        if not grade_sources:\n",
    "            grade_sources = sources\n",
    "\n",
    "        label, text = random.choice(grade_sources)\n",
    "        subject_name, activity_type = split_label(label)\n",
    "\n",
    "        is_last = (question_num == TOTAL_QUESTIONS)\n",
    "\n",
    "        user_prompt = f'''\n",
    "다음 정보를 기반으로 {\"[마지막 질문]\" if is_last else \"[질문]\"}을 생성하라.\n",
    "\n",
    "출처 학년: {selected_grade}학년\n",
    "과목명: {subject_name}\n",
    "활동종류: {activity_type}\n",
    "출처 전문: {label}\n",
    "핵심 내용: {text}\n",
    "\n",
    "해당 학년 희망분야: {selected_career_raw} (키워드: {selected_career_norm})\n",
    "\n",
    "형식:\n",
    "{\"[마지막 질문]\" if is_last else \"[질문]\"}\n",
    "출처: {selected_grade}학년 · {subject_name} ({activity_type})\n",
    "희망분야({selected_grade}학년): {selected_career_raw}\n",
    "핵심 내용: {text}\n",
    "질문:\n",
    "'''\n",
    "        messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            max_tokens=600\n",
    "        )\n",
    "        qtext = resp.choices[0].message.content\n",
    "        print(\"\\n\" + qtext)\n",
    "        messages.append({\"role\": \"assistant\", \"content\": qtext})\n",
    "\n",
    "        answer = input(\"\\n[학생 답변 또는 '다음 질문'] > \").strip()\n",
    "\n",
    "        if answer == \"\":\n",
    "            print(\"\\n⚠ 답변을 입력하지 않았습니다. 같은 질문을 유지합니다.\\n\")\n",
    "            continue\n",
    "\n",
    "        if any(k in answer.lower() for k in SKIP_KEYWORDS):\n",
    "            print(\"\\n[안내] 다음 질문으로 넘어갑니다.\\n\")\n",
    "            question_num += 1\n",
    "            continue\n",
    "\n",
    "        if answer.lower() in (\"exit\", \"quit\"):\n",
    "            print(\"면접을 종료합니다.\")\n",
    "            break\n",
    "\n",
    "        eval_prompt = f'''\n",
    "[학생 답변]\n",
    "{answer}\n",
    "\n",
    "출처 학년: {selected_grade}학년\n",
    "과목명: {subject_name}\n",
    "활동종류: {activity_type}\n",
    "출처 전문: {label}\n",
    "핵심 내용: {text}\n",
    "희망분야({selected_grade}학년): {selected_career_raw}\n",
    "\n",
    "A 모드로 매우 날카롭게 평가하라.\n",
    "'''\n",
    "        messages.append({\"role\": \"user\", \"content\": eval_prompt})\n",
    "\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            max_tokens=900\n",
    "        )\n",
    "        eval_text = resp.choices[0].message.content\n",
    "\n",
    "        # === [다시 답변 요청] 문구는 학생에게 숨김 ===\n",
    "        eval_text_clean = eval_text.replace(\"[다시 답변 요청]\", \"\").strip()\n",
    "        print(\"\\n\" + eval_text_clean)\n",
    "\n",
    "        messages.append({\"role\": \"assistant\", \"content\": eval_text})\n",
    "\n",
    "        score = None\n",
    "        m = re.search(r\"(\\d+)\\s*/\\s*100\", eval_text)\n",
    "        if m:\n",
    "            score = int(m.group(1))\n",
    "\n",
    "        if (score is not None and score < 70):\n",
    "            print(\"\\n⚠ 70점 미만입니다. 같은 질문에 다시 답변하세요.\\n\")\n",
    "            continue\n",
    "\n",
    "        question_num += 1\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 실행\n",
    "##########################################################\n",
    "if __name__ == \"__main__\":\n",
    "    with open(\"wnskadud_structured (1).json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    start_ai_interview(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a8c6b-7d2d-42cc-8c60-f54fa6aeca3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
